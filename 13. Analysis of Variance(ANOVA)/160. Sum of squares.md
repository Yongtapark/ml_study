- ANOVA 테스트에 반하는 영가설
- ANOVA 테스트 뒤의 수학(part1)
- 각 분산 컴포넌트의 자유도
---
## Competing hypothesis of ANOVA

	ANOVA를 생각할 때, 우리는 조작하는 여러 요인과 각 요인 내이 다양한 수준이 있는 표를 생각한다. 
	이 표의 각 셀에는 여러 데이터 포인트가 들어있음.

	그리고 우리는 한 셀에 있는 데이터 포인트들의 평균을 뮤($\mu$) 라고 부를 것임.
	 따라서 MU1은 셀1의 평균, MU2는 셀2의 평균으로 여김.
	이 경우, 셀이 K개 존재하므로, 우리는 MU K를 가지게 됨.

![160.Pasted image 20240927102136](../pic/13.%20Analysis%20of%20Variance(ANOVA)/160.Pasted%20image%2020240927102136.png)
<span style="color:rgb(116, 195, 194)">영가설은 모든 그룹의 평균(ANOVA 테이블의 모든 셀)이 통계적으로 구분되지 않는다는것을 의미</span>

<span style="color:rgb(236, 158, 111)">대립가설은 적어도 한 그룹의 평균이 적어도 다른 한 그룹 또는 셀의 평균과 다르다는것을 의미</span>

	따라서, ANOVA의 영가설은 모든 셀의 평균이 서로 동일하다는것.
	대립가설은 적어도 하나의 평균이 다른 평균과 다르다는 것.

	하지만 어떤 평균이 다른 평균과 다른지에 대한 대답을 즉시 얻을 수 있는것은 아님.
	 그 정보를 얻기 위해서는 추가적인 조사, 즉 사후분석(post hoc)을 해야 함.

---
## Computing and interpreting sum of squares

	ANOVA의 모든 수학은 이 식을 다른 방식으로 표현한 것에 불과함.
	 이것을 제곱합(sum of squares)라고 부름
# $$SS = \sum^\textcolor[rgb]{0.35,0.9,0.9} {n}_{\textcolor {yellow}{i}=1}(\textcolor[rgb]{0.39, 0.58, 0.93} {x}_\textcolor {yellow}{i}-\textcolor[rgb]{0.39, 0.58, 0.93} {\overline{x}})^2$$
	우리는 다양한 종류의 제곱합을 구분할 것임.
	총 제곱합, 그룹간 제곱합, 그룹 내 제곱합이 존재함.
	그러나 모든 제곱합은 기본적으로 이 공식의 변형일 뿐임.

# $$\textcolor[rgb]{1, 0.6, 0.2}\sigma^2 =\frac{1}{\textcolor[rgb]{0.35,0.9,0.9} {n}-1} \sum^\textcolor[rgb]{0.35,0.9,0.9} {n}_{\textcolor {yellow}{i}=1}(\textcolor[rgb]{0.39, 0.58, 0.93} {x}_\textcolor {yellow}{i}-\textcolor[rgb]{0.39, 0.58, 0.93} {\overline{x}})^2$$
	ANOVA 공식은 분산의 공식과 거의 동일함.
	ANOVA는 개별 분산이 아닌, 두 분산의 비율에 관심이 있기 때문에 차이가 생김
---
## ANOVA as a partition of sum of squares

<span style="color:rgb(116, 195, 194)">데이터셋의 총 변동은 각 그룹 내 개체 간 변동과 서로 다른 수준간의 변동의 합이다.</span> 

<span style="color:rgb(236, 158, 111)">Total SS = Within-group SS + Between-group SS</span> 
	SS =  그룹 내 제곱합 + 그룹 간 제곱합

	그룹 내 제곱합은 각 ANOVA 셀, 각 테이블, 각 실험 그룹 내의 개별 변동을 의미
	그룹 간 제곱합은 한 그룹의 모든 구성원과 다른 그룹의 모든 구성원 간의 분산이 얼마나 큰지를 나타냄

<span style="color:rgb(236, 158, 111)">Total SS = <span style="color:rgb(205, 205, 81)">Error SS</span> + Between-group SS</span> 
	 그룹 내 제곱합은 때떄로 오차 제곱합이라고도 불림. 
	이것은 그저 개인간의 변이가 있다는것을 보여줌.

---
## ANOVA as a partition of sum of squares
	우리가 계산할 것은 F 통계량이라고 불리는 것임.
	이것은 ANOVA에서 관심을 갖는 주요 통계량임. 
	 F 통계량은 분산의 두 부분 간의 비율
# $$F = \frac{\textcolor[rgb]{0.35,0.9,0.9} {\text{"Explained" variance}}}{\textcolor[rgb]{1,.45,0}{\text{"Unexplained" variance}}} = \frac{\textcolor[rgb]{0.35,0.9,0.9} {\text{Due to factors}}}{\textcolor[rgb]{1,.45,0}{\text{Natural variation}}}$$
	설명된 분산(Explained variance)은 변동성 또는 제곱합이라고 부른 것
	설명되지 않은 분산(Unexplained variance)은 그룹 내 제곱합 또는 오차 제곱합이라고 부른 것

	Due to factors : ANOVA 요인 안에 기인할 수 있는 모든 분산, 데이터 내의 모든 변동
	실험에서 조작한것이 데이터에 어떤 영향을 미쳤는지 나타내는 변동

	Natural variation : 자연 변동은 통제할 수 없는 개인차나 샘플링 오차 등의 요인에 의해 발생하는 변동

![160.Pasted image 20240927114410](../pic/13.%20Analysis%20of%20Variance(ANOVA)/160.Pasted%20image%2020240927114410.png)
	이 원은 데이터 셋의 모든 분산, 전체변동, 총 제곱합, 모든 분산을 나타냄
	
	ANOVA에서 하는 일은 오차 분산, 또는 모든 분산을 두 부분으로 분할하는 것
		설명된 분산과 설명되지 않은 분산의 비율인 F 통계량을 계산하여, 요인이 데이터의 변동성에 유의미한 영향을 미치는지 판단
		설명 된 분산이 설명되지 않은 분산보다 큰 경우, 우리는 ANOVA가 통계적으로 유의하다고 함.

	따라서, 데이터의 변동이 우리가 실험을 통해 도입한 변동보다 훨씬 큰 경우, 우리는 ANOVA가 통계적으로 유의하지 않다고 말함. -> 이것이 기본 개념

	F 통계량에 대해 흥미로운 점은 결코 음수가 될 수 없다는 점임. -> 공식을 보면 각 항을 제곱한 다음 합산하기 때문

	 F 통계량은 따라서 양수가 될 것이며, 우리는 이 값이 크게나오기를 원함.
		 F 통계량이 클 때는 실험적 조작과 관련된 변동이 많음을 의미함.
		 반면 ,작을 때에는 독립변수를 통해 설명할 수 있는 것보다, 자연적인 개인 변이, 샘플링 변이, 잡음 등으로 인한 변동이 더 많다는 것을 나타냄.

---
## ANOVA as a partition of sum of squares

	one-way-ANOVA 기준 - 한 요인과 여러 수준이 있다고 가정
	그룹 == 수준 

총 제곱합(sum of squares total)
	데이터셋 전체의 총 분산

	자유도는 N-1임. 여기서 N은 총 대상자 수.
	분산 항은 1/(N-1)을 가지고 있으므로, 총 제곱합의 자유도는 N-1
# $$SS_{\text{Total}} = \sum^{\textcolor[rgb]{1,.45,0}{\text{levels}}}_{\textcolor[rgb]{1,.45,0}{j}=1}\sum^{\textcolor {yellow}{\text{individuals}}}_{\textcolor {yellow}{i}=1}(\textcolor[rgb]{0.39, 0.58, 0.93} {x}_{\textcolor {yellow}{i}\textcolor[rgb]{1,.45,0}{j}}-\textcolor[rgb]{0.39, 0.58, 0.93} {\overline{x}})^2\ \ \ \ \ df_\text{Total} = N -1$$
- 전체 데이터의 변동성을 의미하며, 이는 그룹 간 변동과 그룹 내 변동으로 분해될 수 있음
- 요인별 개별들과 전체 데이터의 평균값 사이의 변동성을 구함

그룹 간 제곱합(sum of squares between)
	서로 다른 수준 간의 제곱합 - 요인의 다양한 수준에 기인할 수 있는 변동성

	 levels는 우리가 실험에서 조작하거나 특정 특성에 따라 구성한 그룹

	자유도는 K-1, 여기서 K는 수준의 수.
	그 이유는 우리가 모든 개인에 대해 평균을 내기 때문
# $$SS_{\text{Between}} = \sum^{\textcolor[rgb]{1,.45,0}{\text{levels}}}_{\textcolor[rgb]{1,.45,0}{j}=1}(\textcolor[rgb]{0.39, 0.58, 0.93} {\overline{x}}_{\textcolor[rgb]{1,.45,0}{j}}-\textcolor[rgb]{0.39, 0.58, 0.93} {\overline{x}})^2n_\textcolor[rgb]{1, 0.6, 0.2}{j}\ \ \ \ \ df_\text{Between}=\textcolor[rgb]{1,.45,0}{k}-1$$
- 모든 그룹별 변동성 * 각 그룹별 개인 수 의 합 
- 각 그룹의 평균이 전체 평균과 얼마나 차이나는지를 측정하여 변동을 나타냄

그룹이 다른 그룹과 얼마나 구별되는지

그룹 내 제곱합(sum of squares within)
	오차 제곱항(sum of squared errors)라고 불리기도함.

	자유도는 N-K
	N이 우리가 데이터 내의 모든 개인을 모으거나 고려하고 있기 때문.
	즉, 각 수준 내 모든 개인(individuals)과 모든 수준(levels)을 고려하고 있기 때문에 여전히 우리가 데이터셋에서 측정한 모든 사람을 포함하며, 이것이 N이 됨.

	그리고 K는 1대신 우리가 K개의 다른 평균을 가지고 있기 때문에 나옴. (다른 제곱합은 \overline{x}지만, 여기는 \overline{x}_j임)
	여기서 K는 수준의 수를 나타냄. 따라서 K개의 평균, 즉, K개의 매개변수가 존재
# $$SS_\text{{Within}} = \sum^{\textcolor[rgb]{1,.45,0}{\text{levels}}}_{\textcolor[rgb]{1,.45,0}{j}=1}\sum^{\textcolor {yellow}{\text{individuals}}}_{\textcolor {yellow}{i}=1}(\textcolor[rgb]{0.39, 0.58, 0.93} {x}_{\textcolor {yellow}{i}\textcolor[rgb]{1,.45,0}{j}}-\textcolor[rgb]{0.39, 0.58, 0.93} {\overline{x}}_{\textcolor[rgb]{1,.45,0}{j}})^2\ \ \ \ \ df_\text{Within}= N-\textcolor[rgb]{1,.45,0}{k}$$
- 각 그룹 내의 개별데이터들이 그 그룹의 평균에서 얼마나 떨어져있는지를 측정하여, 요인 외의 자연스러운 변동을 나타냄
- 각 그룹의 개별 데이터가 그 그룹의 평균에서 얼마나 떨어져있는지를 측정함. 이는 요인 외의 자연스러운 변동을 나타내며, 각 그룹 내의 상대적인 변동성을 강조

그룹 내 데이터가 얼마나 일관된 패턴을 가지는지. 즉, 그룹이 얼마나 유의미한 패턴을 가지는지

#### ANOVA는 총 변동성을 그룹 간 변동과 그룹 내 변동으로 분할하여, 요인이 전체 변동성에 미치는 영향을 평가하는 통계적 방법
