---

---
## Code

```python
import numpy as np
import matplotlib.pyplot as plt 
import scipy.stats as stats
from sklearn.decomposition import PCA
import pandas as pd
```

```python
# data urls

marriage_url = 'https://www.cdc.gov/nchs/data/dvs/state-marriage-rates-90-95-99-19.xlsx'
divorce_url  = 'https://www.cdc.gov/nchs/data/dvs/state-divorce-rates-90-95-99-19.xlsx'
```

```python
data = pd.read_excel(marriage_url,header=5)
data
```

```python
# remove irrelevant rows
data.drop([0,52,53,54,55,56,57],axis=0,inplace=True)
data
```

```python
# replace --- with nan
data = data.replace({'---':np.nan})
data
```

```python
# replace nan's with column median
# median으로 대치한 이유는 모든 주의 결혼율이 매년 대략 비슷할것이라는 가정을 했기 때문
# 이상치가 있을 경우 mean이 아닌 median을 사용하여 대체값이 이상치에 영향을 받지 않도록 하기 위함
data.fillna(data.iloc[:,1:].median(), inplace=True)
data
```

```python
# extract to matrices
yearM = data.columns[1:].to_numpy().astype(float)
yearM

statesM = data.iloc[:,0]
statesM
# df 를 np로 변환 -> 강사의 개인적 선호
M = data.iloc[:,1:].to_numpy()
np.round(M,2)
```

```python
# make some plots

fig, ax = plt.subplots(3,1,figsize=(8,5))

# x : 년도, y :해당 주의 1000명당 결혼 건수
ax[0].plot(yearM,M.T)
ax[0].set_ylabel('M. rate (per 1k)')
ax[0].set_title('Marriage rates over time')

# Marriage rates over time 그래프를 보면 값이 유별나게 다른 주(노란색)이 보이는데, 이 이상치 때문에 상대적으로 다른 주들의 데이터가 평평하게 보임
# 그래서 z-정규화를 통해 모든 주 동일한 수 범위를 가지도록 플롯함
# 데이터를 보면, 모든 주의 결혼율이 전반적으로 감소하 있음을 볼 수 있음. 약 30년동안 혼인률은 하락하고 있음.
ax[1].plot(yearM,stats.zscore(M.T))
ax[1].set_ylabel('M. rate (per 1k)')
ax[1].set_title('M. rate (z-norm)')

# notice that x-axis is non-constant
# M(주 별로 묶여있음)의 행의 평균 -> 전체 주들의 연도별 평균을 구함
# 사각형 마커를 통해, x축의 연도가 일정하지 않음을 알 수 있음 -> 90 95 순으로 있다가, 99년부터는 매년 데이터가 존재함
ax[2].plot(yearM,np.mean(M,axis=0),'ks-',markerfacecolor='w',markersize=8)
ax[2].set_xlabel('Year')
ax[2].set_ylabel('M. rate (per 1k)')
ax[2].set_title('State-average')
# QUESTION: Is this the same as the US average?
# Me : yes. 데이터셋에서는 모든 혼인율이 인구 1000명당 비율로 정규화 되어있음. -> 각 주별 데이터가 정규화되어있기 때문에 모든 주의 평균은 전국 평균과 동일함
# 만약 데이터가 정규화되어있지 않았다면, 즉 인구 1000명당 결혼율이 아닌 주별 연도별 결혼 건수의 원본 데이터만 있었다면 가중평균을 계산해야 함
plt.tight_layout()
plt.show()

# 그래프를 보면, 이상하게 시간으 흐를수록 값이 증가하는것처럼 보이지만, df를 보면, 연도를 역순으로 나열하고있기때문에, 반대로 봐야 한다.
# 하지만 선 그래프를 그릴 때는 python이 연도를 자동 정렬하여 오름차순으로 배치한다.
# imshow는 정렬없이 그대로 출력함
plt.imshow(stats.zscore(M,axis=1),aspect='auto')
plt.xticks([])
plt.xlabel('Year')
plt.ylabel('State index')
plt.colorbar()
plt.show()
```
![](222.Pasted%20image%2020241017212520.png)
![](222.Pasted%20image%2020241017212531.png)

```python
# barplot of average marriage rate

# average over time
# 위 그래프[State-average]에서는 연도별 주 전체의 평균 [np.mean(M,axis=0)] 을 구했지만, 여기서는 주별 총 평균[np.mean(M,axis=1)] 을 구함
meanMarriageRate = np.mean(M,axis=1)

# sort index
sidx_M = np.argsort(meanMarriageRate)

fig= plt.figure(figsize=(12,4))
plt.bar(statesM.iloc[sidx_M],meanMarriageRate[sidx_M])
plt.xticks(rotation=90)
plt.ylabel('M. rate (per 1k)')
plt.title('Marriage rates per state')
plt.show()

# QUESTION:
# IS Nevada a non-representative datapoint or error?
# ME : 이 데이터는 비정상적이고 대표성은 부족하지만, 유효한 데이터이므 제거할 이유는 없음. 단지 다른 주들과 차이가 클 뿐


# 강조 : 다양한 방식으로 데이터를 시각화하는것이 중요함.
#       시각화를 통해 데이터를 조사하, 패턴을 파악하, 대표성 없는 비정상적 데이터 이상치를 발견할 수 있음
```
![](222.Pasted%20image%2020241017212550.png)

```python
# show the correlation matrix

# imshow 함수는 축 간의 변화 선형일것이라 가정
# 엄밀 말하자면 이 그래프는 정확하지 않음 (90-95년 사이의 데이터는 없지만 그래프에서는 있는것처럼 표현됨)

# 강사는 모든 요소 강한 상관관계를 보이는 상관행렬을 보면, 이 데이터에 실제 몇개의 패턴이 있는지 궁금하다 함.
# 아마 하나의 특징만으로 전체 데이터셋을 설명할 수 있을지도 모른다고 생각함.
# 이 가능성을 확인하기 위해 PCA를 수행함
plt.imshow(np.corrcoef(M.T),vmin=.9,vmax=1,
    extent=[yearM[0],yearM[-1],yearM[-1],yearM[0]])

plt.colorbar()
plt.show()
```
![](222.Pasted%20image%2020241017212609.png)

```python
# PCA

pca = PCA().fit(M)

# scree plot
# PCA를 수행하는 이유는 스크리 플롯(scree plot)을 분석하 위함임
# 스크리 플롯은 고유값을 나타내며, 각 주성분이 설명하는 분산의 비율을 보여줌
plt.plot(100*pca.explained_variance_ratio_,'ks-',markerfacecolor='w',markersize=10)
plt.ylabel('Percent variance explained')
plt.xlabel('Component number')
plt.title('PCA scree plot of marriage data')
plt.show()

print(100*pca.explained_variance_ratio_[0])
# 그래프를 보면 첫번째 주성분이 거의 모든 분산을 설명함.
# 첫번째 주성분이 98.2%의 분산을 설명함. 즉 하나의 데이 특징만으로 전체 데이터셋을 설명할 수 있음
# 이는 시간이 지남에 따른 전반적인 감소라는 데이터의 특징과 일치하므 놀랍지 않음..
```
![](222.Pasted%20image%2020241017212628.png)

## Repeat for divorce data
```python
# import the data
# 보통은 데이터 불러오기, 처리, 정제, 보간 작업을 한 코드 셀에서 모두 처리하는 것을 추천하지 않음
# 각 코드 라인이 실행될 때마다 데이터를 확인하는 것이 좋음
data = pd.read_excel(divorce_url,header=5)
data.drop([0,52,53,54,55,56,57],axis=0,inplace=True)
data = data.replace({'---':np.nan})
data.fillna(data.iloc[:,1:].median(),inplace=True)

# 이혼 데이터와 결혼 데이터가 완전히 일치하는지 확인을 해야함
yearD = data.columns[1:].to_numpy().astype(float)
statesD = data.iloc[:,0]
D = data.iloc[:,1:].to_numpy()
```

```python
# make some plots

fig, ax = plt.subplots(3,1,figsize=(8,5))

ax[0].plot(yearD,D.T)
ax[0].set_ylabel('D. rate (per 1k)')
ax[0].set_title('Divorce rates over time')

ax[1].plot(yearD,stats.zscore(D.T))
ax[1].set_ylabel('D. rate (per 1k)')
ax[1].set_title('D. rate (z-norm)')

# notice that x-axis is non-constant
ax[2].plot(yearD,np.mean(D,axis=0),'ks-',markerfacecolor='w',markersize=8)
ax[2].set_xlabel('Year')
ax[2].set_ylabel('D. rate (per 1k)')
ax[2].set_title('State-average')

plt.tight_layout()
plt.show()

plt.imshow(stats.zscore(D,axis=1),aspect='auto')
plt.xticks([])
plt.xlabel('Year')
plt.ylabel('State index')
plt.colorbar()
plt.show()


meanDivorceRate = np.mean(D,axis=1)
# sort index
sidx_D = np.argsort(meanDivorceRate)

fig= plt.figure(figsize=(12,4))
plt.bar(statesD.iloc[sidx_D],meanDivorceRate[sidx_D])
plt.xticks(rotation=90)
plt.ylabel('D. rate (per 1k)')
plt.title('Divorce rates per state')
plt.show()


# 결혼과는 달리 이혼은 상대적으 변동이 큼 -> 이혼율은 혼인율에 비해 더 동적인 변화를 보임
# 하지만 색상이 .9에서 포화되 때문에 정확한 값을 알 수 없음.
plt.imshow(np.corrcoef(D.T),vmin=.7,vmax=1, # vmin =.9 -> .7 로 수정
    extent=[yearD[0],yearD[-1],yearD[-1],yearD[0]])

plt.colorbar()
plt.show()

# PCA

pca = PCA().fit(D)

# scree plot
# 이 결과는 시간에 따른 전반적인 감소라는 하나의 주성분에 의해 설명되지만, 그 외에도 다른 요인이 존재함. 명확히 해석하기 어려움
plt.plot(100*pca.explained_variance_ratio_,'ks-',markerfacecolor='w',markersize=10)
plt.ylabel('Percent variance explained')
plt.xlabel('Component number')
plt.title('PCA scree plot of divorce data')
plt.show()

print(100*pca.explained_variance_ratio_[0])
```
![](222.Pasted%20image%2020241017212728.png)
![](222.Pasted%20image%2020241017212738.png)
![](222.Pasted%20image%2020241017212754.png)
![](222.Pasted%20image%2020241017212804.png)
![](222.Pasted%20image%2020241017212815.png)

```python
# cehck if marriage and divorce datasets have the same year/state order

# should be zero
print('Comparison of year vectors: ')
print(np.sum(yearD-yearM))

# should be TRUE
print('')
print('Comparison of states vectors: ')
print(statesM.equals(statesD))
# ... uh oh...

# compare
tmpStateNames = pd.concat([statesM,statesD],axis=1)
print(tmpStateNames)

# find the difference / (array([4]),) -> 5번쨰 row의 값이 다름
np.where(tmpStateNames.iloc[:,0] != tmpStateNames.iloc[:,1])
```

```python
# btw, you can also correlate over states
fig = plt.figure(figsize=(12,12))
plt.imshow(np.corrcoef(D),vmin=0,vmax=1)
plt.xticks(ticks=range(len(statesD)),labels=statesD,rotation=90)
plt.yticks(ticks=range(len(statesD)),labels=statesD)
plt.colorbar()
plt.show()
```
![](222.Pasted%20image%2020241017212841.png)

## Now for some inferrential statistics
```python
# Correlate M and D over time per state
# 혼인율과 이혼율의 연도별 상관관계 계산 -> 각 주의 혼인율과 이혼율 감소 30년동안 서로 상관관계가 있었는지

# Bonferroni crrected threshold
pvalThresh = .05#/51 # 50개의 주와 워싱턴 DC에 대한 본페로니 보정 -> 보수적인 임계값 제공

fig = plt.figure(figsize=(6,10))

color = 'rg'
for si in range(len(statesM)):

    # compute correlation
    r,p = stats.pearsonr(M[si,:],D[si,:])

    # plot the data point
    plt.plot([r,1],[si,si],'-',color=[.5,.5,.5])
    plt.plot(r,si,'ks',markerfacecolor=color[bool(p<pvalThresh)])

plt.ylabel('State')
plt.xlabel('Correlation')
plt.title('Marriage-divorce correlations per state')
plt.yticks(range(len(statesM)),labels=statesD)
plt.tick_params(axis='y',which = 'both',labelleft=False,labelright=True)
plt.xlim([-1,1])
plt.ylim([-1,51])
plt.plot([0,0],[-1,51],'k--')
plt.show()

## 대부분 양의 상관관계를 보이지만 유의미하지 않은 경우(빨간 점)도 존재. 몬타나, 미네소타는 상관관계가 0에 가깝다. 
```
![](222.Pasted%20image%2020241017212909.png)

```python
# have marriage/divorce rates really declined over time?

fig,ax = plt.subplots(2,1,figsize=(12,6))

# initialize slope differences vector
MvsD = np.zeros(len(statesM))

for rowi in range(len(statesM)):

    # run regression (includes the intercept!)
    bM,intercept,r,pM,seM = stats.linregress(yearM,M[rowi,:])
    bD,intercept,r,pD,seD = stats.linregress(yearD,D[rowi,:])

    # normalize beta coefficients
    bM = bM / seM
    bD = bD / seD

    # plot the slope values
    # 여기에는 유의미하지 않은값 몇개가 있으며, 워싱턴DC는 결혼율이 시간이 지남에 따라 증가함
    ax[0].plot([rowi,rowi],[bM,bD],'k')
    ax[0].plot(rowi,bM,'ko',markerfacecolor=color[bool(pM<pvalThresh)])
    ax[0].plot(rowi,bD,'ks',markerfacecolor=color[bool(pD<pvalThresh)])

    # plot the slope differences
    # 양수값을 보이는 주는 이혼율의 감소 더 빠르다는것을 의미
    ax[1].plot([rowi,rowi],[bM-bD,0],'k-',color=[.7,.7,.7])
    ax[1].plot([rowi,rowi],[bM-bD,bM-bD],'ko',color=[.7,.7,.7])

    # store the slope differences for subsequent t-test
    MvsD[rowi] = bM-bD


# make the plot look nicer
for i in range(2):
    ax[i].set_xticks(range(51))
    ax[i].set_xticklabels(statesD,rotation=90)
    ax[i].set_xlim([-1,51])
    ax[i].plot([-1,52],[0,0],'k--')

ax[0].set_ylabel('Decrease per year (norm.)')
ax[1].set_ylabel('$\Delta$M - $\Delta$D')


### ttest on whether the M-vs-D rates are really different
t,p = stats.ttest_1samp(MvsD,0)
df = len(MvsD)-1

# set the title
ax[1].set_title('Marriage vs. divorce: t(%g)=%f, p =%f'%(df,t,p))

plt.tight_layout()
plt.show()

# 지난 30년동안 결혼하는 사람은 줄어들었찌만, 이혼하는 사람은 더 많이 줄어들음
# 하지만 효과는 크기 크 않고, 모든 주에서 동일한 현상이 나타나는것도 아님
```
![](222.Pasted%20image%2020241017212933.png)