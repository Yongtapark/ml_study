- 모수 통계와  순열 기반의 t-test 의미적 차이 (힌트 : $H_0!$)
- 어떻게 순열 테스트가 t-test에서 동작하는지
- p-value를 계산하는 2가지 방법

순열테스트는 비모수적 통계를 수행하는 데 사용할 수 있는 일반적인 프레임워크
t-test, 상관관계 분석에도 사용될 수 있음
이번 섹션엔 t-test만

---
# Inference with permutation vs. parametric stats

![126.Pasted image 20240914190440](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240914190440.png)
추정 기반 유의성(모수적 통계)
- 관찰된 t값을 영가설 하에서 예상되는 t값의 분석적 분포와 비교하여 평가
- 영가설 통계량의 분석적 분포 : 가정에 따라 공식을 사용하여 도출

데이터 기반 유의성(순열 기반 통계)
- 실제 데이터를 기반으로 직접 영가설 분포를 계산, 경험적 분포와 비교하여 관찰된 t-test값을 해석
- 가정이 필요없음
- 어떻게 경험적 영가설 분포를 만들수 있는가?
---
### Mechanism of permutation testing

![126.Pasted image 20240914200316](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240914200316.png)

Measured data
- 현재 데이터는 7개의 데이터 포인트와 2가지 조건을 가지고 있음 (파랑,주황)
- 일반적으로 통계나 과학에서는 조건 간 샘플 크기를 일치시키는것이 좋음

Pooled data
- 측정된 모든 데이터에서 조건을 제거

Shuffled data
- 더 이상 조건이 없는 상태에서 모든 데이터 포인트를하나의 집합으로 합친 후, 조건을 무작위로 다시 할당
- 중요한 점은 데이터 자체는 변경되지 않았음. 데이터 값이나 조건의 개수는 그대로 유지됨
	- 단지, 조건 레이블과 데이터 값 간의 매핑만 무작위로 변경

![126.Pasted image 20240914201455](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240914201455.png)
$\sigma =표준편차$

섞인 데이터를 기반으로 t-statistic 를 계산
- 이때 t-statistic은 0이 될것으로 예상
- 조건을 무작위로 할당했기 때문에 분자는 동일한 값에서 동일한 값을 뺀 값이 됨(?)
- 하지만 실제로는 표본의 변동성으로 0이 아닐 수 있음
	- t-statistic을 계산한 후, 그래프에 표시하고 t-value의 분포를 생성
- 이후 다시 데이터를 섞음
- 여전히 데이터 값이나 레이블은 전혀 변경하지 않음. 단지 기존의 조건 레이블을 무작위로 데이터 포인트에 할당
- t-statistic을 계산 후 분포를 그리는것을 반복
- 이제 영가설 하에서 t-value 분포를 얻게 됨

![126.Pasted image 20240914202943](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240914202943.png)
- 원본 데이터로 돌아가 실제 테스트 통계량을 계산
- 중요한 질문은, 실제 t-statistic이 경험적 영가설 분포와 어떻게 비교되는가 이다.
- 만약 실제 t-statistic 이 이 분포와 멀리 떨어져 있다면, 통계적으로 유의미하다고 말할 수 있음
- 영가설이 참일 경우 이렇게 큰 t-statistic을 관찰하는 것은 매우 드물다고 말할수 있다.

---
### Evaluating significance (p-value)

순열 검정에서 p-value를 계산하는 두가지 방법

1. Z-value 접근법
![126.Pasted image 20240914210958](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240914210958.png)
# $$Z = \frac{\textcolor {yellow}{obs}-E[\textcolor[rgb]{1, 0.6, 0.2}{H_0}]}{std[\textcolor[rgb]{1, 0.6, 0.2}{H_0}]}$$
<span style="color:rgb(116, 195, 194)">정규 분포에 가까운 영가설 분포에 적합하다.</span>

- 중요한 점은, 이 관찰된 값은 실제 이 분포의 일부가 아니라는 것 -> 외워야 함


2. p-value 계산 방법
# $$p_c = \frac{\sum(\textcolor[rgb]{1, 0.6, 0.2}{H_0}>\textcolor {yellow}{obs})}{N_\textcolor[rgb]{1, 0.6, 0.2}{H_o}}$$
<span style="color:rgb(116, 195, 194)">대체적으로 적합함(꼬리에서는 신중해야함)</span> 

- 관찰된 통계값보다 큰 모든 영가설 값들을 합산
	- 영가설 테스트가 관차로딘 값보다 큰 t-value를 얼마나 자주 생성했는지 알고싶어함
	- 1000번 중 10번이 관찰된 값보다 컸다면, p-value는 10/1000 = 0.01이 됨
		- 어느 꼬리를 사용할지 신중하게 결정해야함 0.01일수도, 99.99일수도 있음

---
### Code
비교 데이터 생성
```python
## simulate two distributions 

#number of trials

N= 100

# dataset "A" # 그냥 데이 생성하려 했다고 함.. 별이유 없음
r = np.random.randn(N)
r[r>0] = np.log(1+r[r>0])
dataA = 26-r*10

# get histogram values for later comparison
yA, xA = np.histogram(dataA,20)
xA = (xA[:-1]+xA[1:])/2

# dataset "b"
r = np.random.randn(N)
r[r>0] = np.log(1+r[r>0])
dataB = 30-r*10

# get histogram values for later comparison
yB, xB = np.histogram(dataB,20)
xB = (xB[:-1]+xB[1:])/2

plt.stem(xA,yA,'b',markerfmt='bo',basefmt=' ',label='Data"A"')
plt.stem(xB,yB,'r',markerfmt='ro',basefmt=' ',label='Data"B"')
plt.legend()
plt.show()
```
![126.Pasted image 20240915105037](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240915105037.png)

두 데이터를 합치고, 데이터의 위치를 기록
```python
## mixtrials together 

# concatenate trials
alldata =np.hstack((dataA,dataB))

# condition Labels
conds = np.hstack((np.ones(N),2*np.ones(N))) ## 어느것이 dataA,B인지 식별하기 위헤
```

섞은 순서를 생성, 각 값들의 평균을 비교.
브로드캐스팅으로 인해 conds, fakeconds를 alldata에 직접 저장하지 않더라도 비교가 가능
```python
## generate one Null hyphothesis scenario

# random permutation
fakeconds = np.random.permutation(N*2)

# shuffled condition Labels
fakeconds[fakeconds<N] = 1
fakeconds[fakeconds>1] = 2

# these two means should be different
print([np.mean(alldata[conds==1]), np.mean(alldata[conds==2])])

print([np.mean(alldata[fakeconds==1]), np.mean(alldata[fakeconds==2])])

# 원래 그룹들의 차이와 무작위로 섞은 그룹의 차이가 동일하다고 가정한다.
# 현재는 표본이 1개뿐이므로, 신뢰가 없어 여러번 반복하여 분포를 만들어야 한다.
```
```
[27.629791750422786, 30.46224886915411]
[29.240796489156615, 28.851244130420284]
```

여러번의 반복을 통해 섞은 데이터들의 평균차로 분포를 생성
```python
## and now a distribution of null hypothesis values

nPerms = 1000
permdiffs = np.zeros(nPerms)

for permi in range(nPerms):
    fconds = np.random.permutation(N*2)
    fconds[fconds<N] = 1
    fconds[fconds>1] = 2
    permdiffs[permi] = np.mean(alldata[fconds==2])-np.mean(alldata[fconds==1])

# plot the distribution of H0 values
plt.hist(permdiffs,50)

# and plot the observed value on top
obsval = np.mean(alldata[conds==2])-np.mean(alldata[conds==1])
plt.plot([obsval,obsval],[0,50],'m',linewidth=10)
plt.xlabel('Value')
plt.ylabel('Count')
plt.show

## 이제 질문은, 이 값이 분포의 중심에 충분히 떨어져 있는지, 그래서 우리가 이것을 통계적으로 유의미하다고 판단할 수 있는지 여부
```
![126.Pasted image 20240915110126](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240915110126.png)

p-val을 구하는 2가지 방식
- z-val을 구하여 누적분포함수를 사용하여 p-value 도출
- 분포들 중 관찰값보다 큰 값들만을 구하여 합하고, 총 개수로 나눔 -> p-value 도출
```python
## two methods of evaluating statistical significance

# Z-value
zVal= (obsval-np.mean(permdiffs))/np.std(permdiffs,ddof=1)
p = 1-stats.norm.cdf(abs(zVal))

# p-value count
pCount = sum(permdiffs>obsval)/nPerms

print(p,pCount)
```
둘은 비슷한 값이 도출된다.
```
0.00750897436360265 0.008
```

대수의 법칙, 중심극한을 사용하여 실험 횟수당 얼마나 중심에 접근하는지
```python
k = range(100,5000,10)
av = np.zeros(len(k))

for idx,ki in enumerate(k):
    permdiffs = np.zeros(ki)
    for permi in range(ki):
            fconds = np.random.permutation(N*2)
            fconds[fconds<N] = 1
            fconds[fconds>1] = 2
            permdiffs[permi] = np.mean(alldata[fconds==2])-np.mean(alldata[fconds==1])

    av[idx] = (obsval-np.mean(permdiffs))/np.std(permdiffs,ddof=1)

```
![126.Pasted image 20240916144305](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240916144305.png)
분포를 보면 가우시안인것을 알 수 있음
```python
plt.hist(av,bins=20)
plt.ylabel('Count')
plt.xlabel('Z-value') 
```
![126.Pasted image 20240916144404](../pic/10.The%20t-test%20family/126.Pasted%20image%2020240916144404.png)
