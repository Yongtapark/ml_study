- 왜 여러 변수들 사이의 상관은 'partialed'가 필요할수도 있는지
- 부분상관의 공식
---
### Partial correlation: motivation and effect

![[../pic/12.Correlation/144.Pasted image 20240922135455.png]]
- 예를들어, 1이 날씨이고,  2가 아이스크림, 3이 상어피해라고 가정
- 만약 날씨로 인한 효과를 제거한 후, 아이스크림 콘 소비와 상어 공격간의 상관관계가 무엇인지 알고자 한다면 오른쪽 그림과 같이 볼 수 있음(partial correlation)
	- 변수 1을 제거 했을 때, 실제로 아이스크림 소비와 상어 공격 간의 상관관계는 공유된 분산 때문에 0으로 가게 된다 -> ???

---
### Partial correlation: example application

<span style="color:rgb(118, 147, 234)">사회경제적 상태(m)과 GMAT(standardized business school exam)(g)의 상관관계는 무엇인가?</span>
단, <span style="color:rgb(116, 195, 194)">GMAT 공부에 매진하는 시간(s) 을 제외했을 때</span>

즉, 부유한 아이들이 공부시간에 상관없이 더 높은 GMAT 점수를 받아 경영대학원에 가는것인가? 에 대한 질문

상관관계를 계산해보면 : 
$\textcolor[rgb]{0.39, 0.58, 0.93} {r_{mg} = .7}$ 
$\textcolor[rgb]{0.39, 0.58, 0.93} {r_{sg} = .8}$
$\textcolor[rgb]{0.39, 0.58, 0.93} {r_{ms} = .9}$
- 위 결과는 단순히 해석하기 어렵다.

그래서 몇가지 부분 상관관계를 계산했을 떄 :
$\textcolor[rgb]{0.35,0.9,0.9} {\rho_{mg|s} = .0}$
- 이 부분 상관관계는 s에 의해 공유된 분산을 제거 했을 때, 사회경제적 지위와, GMAT 점수간에는 아무런 관계가 없다는것을 나타냄
$\textcolor[rgb]{0.35,0.9,0.9} {\rho_{sg|m} = .5}$
$\textcolor[rgb]{0.35,0.9,0.9} {\rho_{ms|g} = NA}$ - 사회적 지위와 공부시간 -> 이건 맥락상 말이 안됨. 해석의 의미가 없음

분석의 가능성 범위는 합리적이고 의미 있는 해석 가능한 분석위 범위보다 훨씬 넓다.

---
### Partial correlation: formula
# $$\textcolor[rgb]{0.35,0.9,0.9} {\rho}_{\textcolor[rgb]{1, 0.6, 0.2}{x}\textcolor {yellow}{y}|\textcolor[rgb] {1,.45,0}{z}} = \frac{\textcolor[rgb]{0.39, 0.58, 0.93}{r}_{\textcolor[rgb]{1, 0.6, 0.2}{x}\textcolor {yellow}{y}}-\textcolor[rgb]{0.39, 0.58, 0.93}{r}_{\textcolor[rgb]{1, 0.6, 0.2}{x}\textcolor[rgb] {1,.45,0}{z}}\textcolor[rgb]{0.39, 0.58, 0.93}{r}_{\textcolor {yellow}{y}\textcolor[rgb] {1,.45,0}{z}}}{\sqrt{1-\textcolor[rgb]{0.39, 0.58, 0.93}{r}^2_{\textcolor[rgb]{1, 0.6, 0.2}{x}\textcolor[rgb] {1,.45,0}{z}}}\sqrt{1-\textcolor[rgb]{0.39, 0.58, 0.93}{r}^2_{\textcolor {yellow}{y}\textcolor[rgb] {1,.45,0}{z}}}}$$
z와 공유된 분산을 고려할 때, x와 y간의 부분 상관관계
- 분모 부분 : xy 상관계수 - xz 상관계수 *  yz상관계수 
	- -> 관심있는 변수 - 관심없는 변수 * 관심없는 변수

- x와 z 사이에 상관관계가 없을 때, 즉, y와 z 사이의 상관관계도 0일때 : 분모가 1로 상쇄되어 단순한 xy 상관계수만 남는다.
	- 즉, z에 대한 공유 분산이 존재하지 않는다면, 부분 상관관계는 단순한 xy 상관관계로 줄어든다.

---
### Code
```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.stats as stats
import pingouin as pg # 부분상관을 위한 라이브러리
```

상관계수(r)를 임의 지정하고, 수식으로 계산하여 부분상관 구하기
```python
## the example from the video

# raw correlations
rmg = .7
rsg = .8
rms = .9

# partial correlations
rho_mg_s = (rmg - rsg*rms) / (np.sqrt(1-rsg**2)*np.sqrt(1-rms**2))
rho_sg_m = (rsg - rmg*rms) / (np.sqrt(1-rmg**2)*np.sqrt(1-rms**2))

print(rho_mg_s)
print(rho_sg_m)
```

```python
-0.07647191129018778
0.5461186812727504
```

데이터 프레임을 이용한 상관관계 구하기, pinouin 을 이용한 부분상관 구하기
```python
## now for datasets

N = 76

# correlated datasets
x1 = np.linspace(1,10,N) + np.random.randn(N)
x2 = x1+np.random.randn(N)
x3 = x1+np.random.randn(N)

# let's convert theses data to a pandas frame
df = pd.DataFrame()
df['x1'] = x1
df['x2'] = x2
df['x3'] = x3

# compute the 'raw' correlation matrix
cormatR = df.corr()
print(cormatR)

# print out one value
print('  ')
print(cormatR.values[1,0])

# partial correlation # covar = 우리가 제거하려는 변수
# x1, x2 사이의 부분 상관관계를 계산하고 있으며, x3과의 공유된 분산을 제거하고 있음
pc = pg.partial_corr(df,x='x1',y='x2',covar='x3')
pc = pg.partial_corr(df,x='x3',y='x2',covar='x1')
print(' ')
print(pc)
```

```
          x1        x2        x3
x1  1.000000  0.941551  0.950439
x2  0.941551  1.000000  0.906446
x3  0.950439  0.906446  1.000000
  
0.9415512501939381
 
          n         r          CI95%     p-val
pearson  76  0.110357  [-0.12, 0.33]  0.345912
```

raw 상관행렬과 부분 상관행렬을  시각화
```python
# visualize the matrices

fig,ax = plt.subplots(1,2,figsize=(6,3))

# raw correlations
ax[0].imshow(cormatR.values,vmin=-1,vmax=1)
ax[0].set_xticks(range(3))
ax[0].set_yticks(range(3))

# add text
for i in range(3):
    for j in range(3):
        ax[0].text(i,j,np.round(cormatR.values[i,j],2), horizontalalignment= 'center')


# partial correlations
partialCorMat = df.pcorr()
ax[1].imshow(partialCorMat.values,vmin=-1,vmax=1)
ax[1].set_xticks(range(3))
ax[1].set_yticks(range(3))

# 3번째 변수에 기인하는 분산을 제거했을때
for i in range(3):
    for j in range(3):
        ax[1].text(i,j,np.round(partialCorMat.values[i,j],2), horizontalalignment= 'center')

plt.show()

# 만약, x3를 독립적인 데이터 변경한다면 상관고 부분상관이 거의 비슷함을 관찰할 수 있는데, 이는 x3가 다른 변수들과 공유된 분산이 없기 때문에
# 제거한다 해도 큰 차이가 나지 않는다.
```
![[../pic/12.Correlation/144.Pasted image 20240922212119.png]]
