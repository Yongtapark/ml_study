 - 상관관계(correlation)와 공분산(covariance)의 차이
 - 공식들

---
### Covariance vs. correlation: what's the diff?

<span style="color:rgb(118, 147, 234)">공분산은 두 변수간의 선형관계를 측정하는 단일숫자이다.</span>
- 상관관계의 설명과 매우 유사
- 실제로 상관관계를 계산하려면, 먼저 공분산을 계산해야함
	- 그 후 공분산을 적절히 정규화하면 된다.

<span style="color:rgb(116, 195, 194)">상관관계는 공분산이 스케일링된것이다.</span>
![[../pic/12.Correlation/137.Pasted image 20240918080913.png]]

---
### Formula for covariance and correlation
# $$\textcolor[rgb]{0.39, 0.58, 0.93} {c} = \frac{1}{n-1}\sum^n_{i=1}(\textcolor[rgb]{1, 0.6, 0.2}{x_i}-\textcolor[rgb]{1, 0.6, 0.2}{\overline{x}})(\textcolor {yellow}{y_i}-\textcolor {yellow}{\overline{y}})$$
- n-1인 이유는 평균을 빼기 때문이다. 이는 자유도와 연관된듯?

# $$\textcolor[rgb]{0.35,0.9,0.9} {r} = \frac{\sum^n_{i=1}(\textcolor[rgb]{1, 0.6, 0.2}{x_i}-\textcolor[rgb]{1, 0.6, 0.2}{\overline{x}})({\textcolor {yellow}{y_i}-\textcolor {yellow}{\overline{y}}})}{\sqrt{\sum^n_{i=1}(\textcolor[rgb]{1, 0.6, 0.2}{x_i}-\textcolor[rgb]{1, 0.6, 0.2}{\overline{x}})^2\sum^n_{i=1}(\textcolor {yellow}{y_i}-\textcolor {yellow}{\overline{y}})^2}}$$
- x,y가 동일값이라고 했을 때, r= 1이 되므로 이 방식이 옳은 정규화임을 증명한다.
- 공분산의 스케일링된 버전이 상관관계라고 했는데, $\frac{1}{n-1}$ 은 어디에 갔는가?
	- 분자와 분모에 모두 $\frac{1}{n-1}$이 존재하면 서로 상쇄되기 때문에 없어진다.

기억할것 : 상관계수를 통계적으로 유의미하게 해석할수 없음

---
### P-value of correlation coefficient
상관계수에서 p값을 계산하는 방법
# $$t_{n-2} = \frac{\textcolor[rgb]{0.35,0.9,0.9} {r}\sqrt{n-2}}{1-\textcolor[rgb]{0.35,0.9,0.9} {r}^2}$$
<span style="color:rgb(118, 147, 234)">통계적 유의성은 상관관계와 데이터포인트의 수의 강도에 따른 t-value의 값으로 계산된다.</span>

- n-2의 자유도를 가진 t-value
- n을 키울수록 t값은 증가하겠지만, 그 증가량은 제곱근때문에 크지않다.
- r이 1또는 -1에 가까워질수록 분모는 0에 가까워진다.
- 즉, n과 r은 크면 클수록 t 값이 최대화된다. -> p값이 작아진다 -> 유의미해진다.
---
### Code1

데이터 생성
```python
## simulate data

N = 66

# generate correlated data
x = np.random.randn(N)
y = x + np.random.randn(N)

# plot the data
plt.plot(x,y,'kp',markerfacecolor='b',markersize=12)
plt.xlabel('Variable X')
plt.ylabel('Variable Y')
plt.xticks([])
plt.yticks([])
plt.show()
```
![[../pic/12.Correlation/137.Pasted image 20240918105214.png]]

공분산을 구하는 3가지 방법을 소개
```python
## compute covariance

# precompute the means
meanX = np.mean(x)
meanY = np.mean(y)

### the loop method # 공식을 그대로 구현한 방식
covar1 = 0
for i in range(N):
    covar1 = covar1 + (x[i]-meanX)*(y[i]-meanY)

# and now for the normalization 
covar1 = covar1/(N-1)

### the linear albebra method # 선형대수 방법, 내적은 요소 간 곱의 합이다.
xCent = x-meanX
yCent = y-meanY
covar2 = np.dot(xCent,yCent)/(N-1)

# the python method # 파이썬 코드
covar3 = np.cov(np.vstack((x,y)))

print(covar1)
print(covar2)
print(covar3) # 파이썬에서는 2x2 행렬로 반환함(x 분산,y 분산, 공분산)
```
```
1.1622326584875022
1.1622326584875025
[[1.04891693 1.16223266]
 [1.16223266 1.98523991]]
```

상관계수 계산
```python
## now for the correlation

### the long method
corr_num = sum((x-meanX)*(y-meanY))
corr_den = sum((x-meanX)**2) * sum((y-meanY)**2)
corr1 = corr_num/np.sqrt(corr_den)

### the python method
corr2 = np.corrcoef(np.vstack((x,y)))

print(corr1)
print(corr2) # 상관계수, 자기자신과의 상관계수
```
```
0.8054081684911966
[[1.         0.80540817]
 [0.80540817 1.        ]]
```

z-scored된 두 변수의 공분산을 구했을 때, 공분산과 상관계수가 동일함을 보여줌
```python
## correlation as normalized covariance
# 선형대수 방법을 이용하여 z-score된 x,y의 공분산을 구했는데, 이 값은 현재 상관계수와 동일한 값이다.
# 상관계수 자체가 공분산을 스케일링한것이니, z-score 스케일링된 값의 공분산은, 결국 상관계수가 되는건가
# 아래코드는 z-scored된 변수는 상관계수와 공분산이 동일하다는것을 보여줌
xn = stats.zscore(x,ddof=1)
yn = stats.zscore(y,ddof=1)

corr3 = np.dot(xn,yn)/(N-1)

print(corr3)
```
```
0.8054081684911967
```

상관계수와 샘플 크기에 따른 p-value의 변화
```python
## 2D t-value space based on r and n

# define parameters
r = np.linspace(-1,1,248)
n = np.round(np.linspace(5,200,73))

# initialize t-value matrix
tmatrix = np.zeros((len(r),len(n)))
pmatrix = np.zeros((len(r),len(n)))

for ri in range(len(r)):
    for ni in range(len(n)):

        # the t-value, split into num/den
        num = r[ri]*np.sqrt(n[ni]-2)
        den = 1-r[ri]**2

        tmatrix[ri,ni] = num/den
        pmatrix[ri,ni] = 1-stats.t.cdf(abs(num/den),n[ni]-2)

# Soooo curious to see it!
plt.imshow(tmatrix,vmin=-3,vmax=3,extent=[n[0],n[-1],r[0],r[-1]],aspect='auto')
plt.contour(pmatrix<.05,1,colors='k',extent=[n[0],n[-1],r[0],r[-1]])
plt.xlabel('Sample size')
plt.ylabel('Correlation coefficient')
plt.title('T-values from different r-n combos')
plt.show()

# 검은 선 위/아래쪽은 유의미한 p-value결과값들
# 즉, 동일한 상관계수를 가지더라도, 샘플 크기가 늘어나면, 유의미해진다.
```
![[../pic/12.Correlation/137.Pasted image 20240918105523.png]]

stats 라이브러리를 이용하면 상관계수와 p-value를 함께 얻을수있다.
판다스 라이브러리의 상관계수는 p-value를 반환하지 않음
```python
#final note on statistical significance
# numpy의 상관계수 함수는 p-value를 반환하지 않음
# 첫번째 값은 상관계수, 두번째 값은 p-value

r,p = stats.pearsonr(x,y)
print(r,p)
```
```
0.8054081684911968 3.5484783531262847e-16
```

---

Code2 : 상관계수를 지정한 데이터를 생성하는 방법

```python
## simulate data

# data simulation parameters
N = 100
r = .6 # desired correlation coefficient

# start with random numbers
x = np.random.randn(N)
y = np.random.randn(N)

# impose the correlation on y
# 원하는 상관계수에 맞는 y값 데이터로 변경
y = x*r + y*np.sqrt(1-r**2)

# plot the data
plt.plot(x,y,'kp',markerfacecolor='b',markersize=12)
plt.xlabel('Variable X')
plt.ylabel('Variable Y')
plt.xticks([])
plt.yticks([])
plt.show()
```
![[../pic/12.Correlation/137.Pasted image 20240918113242.png]]

이렇게 만든 데이터는 표본 변동성때문에 실제 목표 상관계수와는 차이가 있음
```python
# compute the empirical correlation
# 목표로한 r 값과 경험적 r값이 차이 나는 이유는 여기서의 r은 일종의 이론적 상관계수이기 때문
# 경험적 r값은 현재 난수에서 추출하므로 차이가 날 수 있음. 데이터가 무한하다면 r값과 경험적r 값이 일치할것이다.

empR = np.corrcoef(x,y)
print('Desired r=%g, empirical r=%g'%(r,empR[0,1]))
```

```
Desired r=0.6, empirical r=0.550648
```

데이터 크기에 따른 에러율 그래프
```python
## Test the errors as a function of N
# 여기서 오류는 우리 지정한 상관계수와 랜덤 데이터에 얻은 상관계수간의 차이를 의미

# range of sample sizes
Ns = np.round(np.linspace(5,400,123)).astype(int)

# theoretical correlation coefficient (fixed)
r = .6

# initialize
corrs =np.zeros(len(Ns))

# run the experiment!
for ni in range(len(Ns)):
    x = np.random.randn(Ns[ni])
    y= x*r + np.random.randn(Ns[ni])*np.sqrt(1-r**2)
    # 현재는 실제 상관계수가 아닌 실제 상관계수와 이론적 상관계수의 차(오류)를 구하고자 함
    # 오류값을 제곱하는 이유는 두가지다.
    # 하나는 제곱 오 항이 통계에 흔히 사용된다는 점 - ANOVA, GLM, 회귀분석 등
    # 음수 부호를 없애기 위해
    corrs[ni] = (r-np.corrcoef(x,y)[0,1])**2

plt.stem(Ns,corrs,'ko--')
plt.xlabel('Sample size')
plt.ylabel('squared divergence')
plt.show()
```
![[../pic/12.Correlation/137.Pasted image 20240918113518.png]]
