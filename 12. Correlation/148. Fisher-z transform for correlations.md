- 왜 상관계수가 가끔은 변환이 필요한지
- Fisher-Z 변환의 공식
- 동일한 짧은 공식

상관계수는 -1 ~+1 사이 값으로 제한됨

---
### Why do correlations need a transformation?
![../pic/12.Correlation/148.Pasted image 20240923113649.png](../pic/12.Correlation/148.Pasted%20image%2020240923113649.png)

<span style="color:rgb(116, 195, 194)">상관계수는 -1부터 1까지 균등하게 분포되어있다.</span>
<span style="color:rgb(205, 205, 81)">많은 분석 방법은 가우시안 분포를 기본 가정으로 한다.</span> 

---
### How does the Fisher-Z transform work?
# $$z_\textcolor[rgb]{0.35,0.9,0.9} {r} =\frac{1}{2}\ln(\frac{1+\textcolor[rgb]{0.35,0.9,0.9} {r}}{1-\textcolor[rgb]{0.35,0.9,0.9} {r}}) =\text{arctanh}(\textcolor[rgb]{0.35,0.9,0.9}{r})$$
arctanh(r) : 상관계수의 아크탄젠트 ??

---
### The effect of the Fisher-z transform

![../pic/12.Correlation/148.Pasted image 20240923115723.png](../pic/12.Correlation/148.Pasted%20image%2020240923115723.png)
- 중간 범위의 값은 큰 변화가 없음
- 하지만 양 끝에 가까울수록 Fisher-Z 변환은 더 큰 변화를 가짐


Fisher-z가 꼭 필요한것은 아님

필요할 때 : 
- 여러 상관관계를 계산하거나
- 많은 개체에 대해 상관관계를 계산할 때
- 그 상관계수르들을 종합적으로 분석할 때
- t-test, ANOVA 같은 분석에서 정규 분포를 가정할 때
---
### Code

엔스컴 콰르텟 생성, 동일 피어슨, 스피어만 값 비교
```python
## Anscobe's quartet

anscombe = np.array([
     # series 1     series 2      series 3       series 4
    [10,  8.04,    10,  9.14,    10,  7.46,      8,  6.58, ],
    [ 8,  6.95,     8,  8.14,     8,  6.77,      8,  5.76, ],
    [13,  7.58,    13,  8.76,    13, 12.74,      8,  7.71, ],
    [ 9,  8.81,     9,  8.77,     9,  7.11,      8,  8.84, ],
    [11,  8.33,    11,  9.26,    11,  7.81,      8,  8.47, ],
    [14,  9.96,    14,  8.10,    14,  8.84,      8,  7.04, ],
    [ 6,  7.24,     6,  6.13,     6,  6.08,      8,  5.25, ],
    [ 4,  4.26,     4,  3.10,     4,  5.39,      8,  5.56, ],
    [12, 10.84,    12,  9.13,    12,  8.15,      8,  7.91, ],
    [ 7,  4.82,     7,  7.26,     7,  6.42,      8,  6.89, ],
    [ 5,  5.68,     5,  4.74,     5,  5.73,     19, 12.50, ]
    ])

# plot and compute correlations
fig,ax = plt.subplots(2,2,figsize=(6,6))
ax = ax.ravel()

for i in range(4):
    ax[i].plot(anscombe[:,i*2],anscombe[:,i*2+1],'ko')
    ax[i].set_xticks([])
    ax[i].set_yticks([])
    corr_p = stats.pearsonr(anscombe[:,i*2],anscombe[:,i*2+1])[0]
    corr_s = stats.spearmanr(anscombe[:,i*2],anscombe[:,i*2+1])[0]
    ax[i].set_title('r_p = %g, r_s = %g'%(np.round(corr_p*100)/100, np.round(corr_s*100)/100))

plt.show()
```
![148.Pasted image 20240923135832.png](148.Pasted%20image%2020240923135832.png)

균일 분포였던 피어슨 분포를 Fisher-Z 변환을 통해 정규 분포로 전환
```python
## Fisher-Z transform

# simulate correlation coefficients
N = 10000
r = 2*np.random.rand(N)-1 # 0,1 사이의 난수 생성 *2 -> 0,2 사이 난수 생성 -1 -> -1,1 사이 난수 생성

# Fisher-Z
fz = np.arctanh(r)

# overlay the Fisher-Z
y,x = np.histogram(fz,30)
x= (x[1:]+x[0:-1])/2
plt.bar(x,y)

# raw correlations
y,x = np.histogram(r,30)
x = (x[1:]+x[0:-1])/2
plt.bar(x,y)
```
![148.Pasted image 20240923140014.png](148.Pasted%20image%2020240923140014.png)

피어슨 계수에서 Fisher-z로 변환 할 때 값이 어떻게 변하는지를 시각화
```python
plt.plot(range(N),np.sort(r),'o',markerfacecolor='w',markersize=7)
plt.plot(range(N),np.sort(fz),'o',markerfacecolor='w',markersize=7)
plt.ylabel('Value')
plt.legend(('Correlation','Fisher-Z'))

# zoom in
# plt.ylim([-.8,.8])
plt.show()
```
![148.Pasted image 20240923140119.png](148.Pasted%20image%2020240923140119.png)

----
## Code2 : unsupervised 
부트스트랩을 이용한 상관계수 샘플링 및 신뢰구간 시각화

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon

# 1. 데이터 생성
n = 100
x = np.random.randn(n)
y = x + np.random.randn(n)

# 원본 상관계수 계산
origin_pear, _ = stats.pearsonr(x, y)
print(f"원본 상관계수: {origin_pear}")

# 2. 부트스트랩핑
n_bootstraps = 1000
bootstrapped_corrs = []

for _ in range(n_bootstraps):
    indices = np.random.choice(np.arange(n), size=n, replace=True)  # 부트스트랩 샘플링
    pear, _ = stats.pearsonr(x[indices], y[indices])               # 샘플링된 데이터의 상관계수
    bootstrapped_corrs.append(pear)

# 3. 신뢰 구간 계산
lower_bound = np.percentile(bootstrapped_corrs, 2.5)
upper_bound = np.percentile(bootstrapped_corrs, 97.5)
diff = upper_bound-lower_bound
print(f"95% 신뢰구간 : [{lower_bound}, {upper_bound}]")

# 4. 부트스트랩 상관계수의 평균
samplemean = np.mean(bootstrapped_corrs)

plt.plot(x,y,'o')
plt.title('pear : %g'%origin_pear)
plt.show()

# 5. 히스토그램 및 상관계수 시각화
plt.hist(bootstrapped_corrs, bins=40, alpha=0.75)

y = np. array([[lower_bound,0],[upper_bound,0],[upper_bound,100],[lower_bound,100]])
p = Polygon(y,facecolor='g',alpha=.3)
plt.gca().add_patch(p)

plt.plot([origin_pear, origin_pear], [0, 100], 'k:', linewidth=3, label='Original Pearson r')
plt.plot([samplemean, samplemean], [0, 100], 'r--', linewidth=3, label='Mean of Bootstrapped r')
plt.xlim([samplemean-.2,samplemean+.2])
plt.legend()
plt.title('Bootstrapped Pearson Correlations')
plt.show()
```
![](148.Pasted%20image%2020240924093435.png)
![](148.Pasted%20image%2020240924093501.png)

상관계수에 따른 신뢰구간 너비의 변화
상관계수가 양 극에 가까워 질 수록 너비가 감소하는 것을 알 수 있다.
```python
n = 100
corrs = np.linspace(-1,1,50)
boots = 200
ci_diffs=[]

for index,corr in enumerate(corrs):
    x = np.random.randn(n)
    y = np.random.randn(n)
    y = x*corr+y*np.sqrt(1-corr**2)
    corr_list = []
    for i in range(boots):
        sel = np.random.choice(range(n),n)
        corr_list.append(stats.pearsonr(x[sel],y[sel])[0])

    diff = np.percentile(corr_list,97.5)-np.percentile(corr_list,2.5)
    ci_diffs.append(diff)

plt.plot(corrs,ci_diffs,'bo')
plt.xlabel('corrs')
plt.ylabel('ci_diffs')
plt.show()
```

![](148.Pasted%20image%2020240924093606.png)
