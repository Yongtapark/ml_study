- 언제 켄달 상관계수가 적절한지
- 켄달 상관계수의 기본 공식

이 방법은 일반적으로 사용하는것이 아님

---
### Kendall's correlation

<span style="color:rgb(118, 147, 234)">순서형 데이터(순서가 존재하지만, 각 수준 간의 고정된관계는 없음)에 사용됨</span>

<span style="color:rgb(116, 195, 194)">Examples: 교육, 영화 평점</span>
- 교육을 예로 들 때, 중학교, 고등학교, 학사, 석사, 박사는 범주에 해당함
	- 이들 간의 의미 있는 관계가 있지만, 본질적으로 고정된 수치적 관계는 존재하지 않음
	- 예를들어, 중학교와 고등학교의 차이가, 석사와 박사의 차이와 같지는 않다는 점
- 별점의 경우, 1~5까지의 별점이 존재하지만, 1점과 2점의 평가를 합친다고해서 그것이 3점의 평가와 동일하지 않음

숫자를 할당할 수 있지만, 고정된 관계는 없음
이런 데이터를 다른 종류의 데이터와 상관시키고 싶다면, 켄달 상관계수가 적합함

---
### How it works

<span style="color:rgb(118, 147, 234)">데이터를 랭크일치(각 변수의 값 간의 상대적인 부호)로 변환</span>

<span style="color:rgb(205, 205, 81)">"Kendall tau-b" 는 동률에 대한 조정이 포함되어있으며, 실제로 많이 사용된다.</span> 

<span style="color:rgb(236, 158, 111)">해석은 피어슨이나 스피어만과 동일하다</span> 
- 켄달 타우는 -1에서 +1까지 값을 가짐

# $$ \textcolor[rgb]{1, 0.6, 0.2}{\tau} = K^{-1}\sum{\mathrm{sgn}({\textcolor[rgb]{0.39, 0.58, 0.93} {\tilde{x}}_i-\textcolor[rgb]{0.39, 0.58, 0.93} {\tilde{x}}_{i:}})\mathrm{sgn}({\textcolor[rgb]{0.35,0.9,0.9} {\tilde{y}}_i-\textcolor[rgb]{0.35,0.9,0.9} {\tilde{y}}_{i:}})}$$
sgn(사인 | 시그넘) : 음수일 경우 -1, 0일경우 0, 양수일 경우 1을 반환

$\tilde{x}$ = x의 랭크 버전

각 변수의 랭크를 계산한 후, 데이터의 나머지 지점에 대해 각 요소 i의 부호를 계산한다는 의미

':' : 파이썬의 : 문법을 혼용했음..

$x_i$가 $\tilde{x}_{i:}$ 보다 크고, $y_i$가 $\tilde{y}_{i:}$ 보다 크다면, 양수 * 양수 이므로 양수가 됨.

이때 양수 * 양수의 경우가 바로 일치(concordance)를 의미함
- x,y가 자신의 랭크 분포에 비해 상대적으로 작거나 클 때, 우리는 많은 양수부호(+1)를 얻게 됨.
- x,y의 크기가 다르다면 음수가 나오며, 전체 값을 줄이게 됨

이들의 합은 1이 아닌 정수값임
- 데이터 벡터의 길이에 따라 임의로 큰 값이될 수도 있음 -> 그래서 정규화 인자 K를 사용함
	- K에 대한 정의는 하지않음 -> 결론은 총합이 1이 되도록 스케일링함

---
### Code

데이터 생성 및 상관계수 측정
```python
## generate some data!
# 교육 수준과 다큐멘터리 평점의 상관관계를 계산

N = 40

# movie ratings
docuRatings = np.random.randint(low=1,high=6,size=N)

# education level (1-4, correlated with docuRatings)
eduLevel = np.ceil((docuRatings+np.random.randint(low=1,high=5,size=N))/9*4)

# compute the correlations
cr = [0,0,0]
cr[0] = stats.kendalltau(eduLevel,docuRatings)[0]
cr[1] = stats.pearsonr(eduLevel,docuRatings)[0]
cr[2] = stats.spearmanr(eduLevel,docuRatings)[0]

# round for convenience
cr = np.round(cr,4)

# plot the data
plt.plot(eduLevel+np.random.randn(N)/30,docuRatings+np.random.randn(N)/30,'ks',markersize=10,markerfacecolor=[0,0,0,.25])
plt.xticks(np.arange(4)+1)
plt.yticks(np.arange(5)+1)
plt.xlabel('eduLevel')
plt.ylabel('docuRatings')
plt.grid()
plt.title('$r_k$ = %g, $r_p$=%g, $r_s$=%g'%(cr[0],cr[1],cr[2]))
plt.show()
```

![Pasted image 20240924141247](../pic/12.Correlation/149.Pasted%20image%2020240924141247.png)

영가설 하의 오차 추정 상관관계
```python
## correlation estimation errors under H0
# 1000번의 반복을 통해 새로운 가짜 데이터를 생성하고, 그 데이터들을 상관분석하는 실험
# 이 실험의 핵심은 이론적으로 모든 상관계수가 0이 되어야 한다는 것
# 무작위 샘플링 변동성 때문에 모든 값이 0이 되지는 않지만, 상관계수가 0에 가까울것으로 기대

# 따라서 각 상관계수 측정값이 0에서 얼마나 떨어져 있는지를 통해 추정 오류가 
# 가장 적은 상관계수 측정법을  확인할 수 있음
numExprs = 1000
nValues = 50
nCategories = 6

c = np.zeros((numExprs,3))

for i in range(numExprs):

    # create data
    x= np.random.randint(low=0,high=nCategories,size=nValues)
    y= np.random.randint(low=0,high=nCategories,size=nValues)

    # store correlations
    c[i,:] = [stats.kendalltau(x,y)[0],
             stats.pearsonr(x,y)[0],
             stats.spearmanr(x,y)[0]]
print(c)
```

```
[[-0.20662951 -0.24265026 -0.2748583 ]
 [-0.00778974 -0.00492255 -0.01567158]
 [ 0.05965931  0.06587328  0.06232608]
 ...
 [ 0.          0.00863874 -0.00310328]
 [-0.0525701  -0.07507814 -0.07079962]
 [-0.24342792 -0.30918707 -0.30665925]]
```

각 상관계수 메서드에 대한 비교. 상관계수가 크면 클수록 그 차이는 벌어진다.
```python
## show the graphs
# 제곱을 하는 이유 -> 양수인지 음수인지 중요하지 않고, 얼마나 0에 가까운지 알고싶기 때문

# 이 추정 데이터에서, 켄달 상관계수는 가장 작은 추정 오류를 제공할 뿐만 아니라, 가장 적은 분산을 보임
plt.bar(range(3),np.mean(c**2,axis=0))
# errorbar의 yerr 는 오류의 범위를 나타내며 보통 표준편차, 표준오차를 사용한다.
plt.errorbar(range(3),np.mean(c**2,axis=0),yerr=np.std(c**2,ddof=1,axis=0))
plt.xticks(range(3),('Kendall','Pearson','Spearman'))
plt.ylabel('Squared correlation error')
plt.title('Noise correlation ($r^2$) distributions')
plt.show()

# 1000개의 실험 중에서 처음 100개의 켄달, 피어슨, 스피어만 상관계수를 보여줌
# 중요한점은 세 가지 측정법 모두 위 아래로 변동한다는것 
# -> 각 반복마다 동일한 무작위 숫자가 세가지 상관계수 측정법에 의해 계산됨. 그렇기에 위아래로 출렁이는것
plt.plot(c[:100,:],'s-')
plt.xlabel('Experiment number')
plt.ylabel('Correlation value')
plt.legend(('K','P','S'))
plt.show()

# 상관행렬을 보여줌
# 이 측정 값들이 서로 크게 다르지 않다는것을 보여줌
# 여기서 가장 작은 상관계수는 .99로 매우 작음 -> 서로 강한 상호 상관관계를 가지고 있음
plt.imshow(np.corrcoef(c.T),vmin=.9,vmax=1)
plt.xticks(range(3),['K','P','S'])
plt.yticks(range(3),['K','P','S'])
plt.colorbar()
plt.title('Correlation matrix')
plt.show()

# 현재 영가설에 대한 분석이기 때문에, 상관관계가 0ㅇ 가까워서 상관계수 방법들의 값 차이가 크게 나지 않았지만,
# 상관계수가 높으면 높을수록 상관계수 방법들간의 차이는 커진다.
```
![Pasted image 20240924141500](../pic/12.Correlation/149.Pasted%20image%2020240924141500.png)
![Pasted image 20240924141511](../pic/12.Correlation/149.Pasted%20image%2020240924141511.png)
![Pasted image 20240924141521](../pic/12.Correlation/149.Pasted%20image%2020240924141521.png)

---
### Code : unsupervised

범주형 데이터에서 상관계수가 변화할 떄, 그를 측정하는 상관계수 함수 켄달, 피어슨의 계수값 비교
```python
N = 300
r_range = np.linspace(-1,1,1000)
err = np.zeros((len(r_range),3))
 
for i,r in enumerate(r_range):
    c = np.zeros((30, 3))
    for j in range(30):
        x = np.random.randint(low=1,high=6,size=N)
        # r*x : 1에 가까울수록 r과 가까워지므로 상관관계가 높아짐
        #  * np.sqrt(1-r**2) : 계수가 0에 가까울수록 노이즈를 키우고, 양극단으로 갈수록 노이즈를 줄이는 역할
        y = np.ceil(r*x + np.random.randint(1,10,N)*np.sqrt(1-r**2))
        
        r_p = stats.pearsonr(x,y)[0]
        r_k = stats.kendalltau(x,y)[0]
        c[j,:] = [(r_p - r_k)**2,r_p,r_k]

    err[i,0] = np.mean(c[:,0])
    err[i,1] = np.mean(c[:,1])
    err[i,2] = np.mean(c[:,2])



     
plt.plot(r_range,err[:,0],'.')
plt.xlabel("r")
plt.ylabel("$error^{2}$")
plt.title("$(r_{s} - r_{k})^{2}$ in different r")
plt.show()

plt.plot(r_range, err[:, 1], label='r_k')
plt.plot(r_range, err[:, 2], label='r_p')
plt.xlabel('r')
plt.ylabel('c')
plt.title('$r_s,r_k$ in different r')
plt.legend()
plt.show()
```

![Pasted image 20240925101619](../../Pasted%20image%2020240925101619.png)
![Pasted image 20240925101631](../../Pasted%20image%2020240925101631.png)
