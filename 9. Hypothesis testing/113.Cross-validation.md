- cross-validation이 무엇ㅣ지
- 훈련과 데이터를 테스트는것
- 교차검증의 추정
---
### Cross-validation
![[113.Pasted image 20240911093944.png]]
- 데이터를 일정부분 나누어 훈련, 평가 -> 훈련, 평가 데이터 변경해가며 반복

-> <span style="color:rgb(116, 195, 194)">K-fold cross validation</span> 
- 매번 10%를 테스트셋으로 사용한다면 10번의 반복이 필요함

<span style="color:rgb(230, 122, 122)">적절한 횟수는 무엇인가? 보통 10또는 20</span> 
양 극단으로 갈수록 결과가 나쁨
- k값이 높을수록 결과가 견고해지지만, 너무많은 경우 (ex.100겹)  개별 데이터 청크가 너무 작아질 수 있음.
- 그래서 정확도도 불안정해질 수도 있고, 노이즈와 샘플링 변동성에 의해 결과에 영향
- 일반적으로 10~20사이의 값이 흔히 사용됨

훈련세트나 테스트 세트에 편향이 발생하지 안도록 하는것이 중요
- 무작위 추출되도록 해야 함

![[114.Pasted image 20240911094857.png]]
- 일반적으로는 이렇게 랜덤하게 추출함

----
### Uses of cross-validation

분산 추정 (e.g., 신뢰구간)
<span style="color:rgb(118, 147, 234)">잭나이핑이라고도 불림. 훈련세트가 다른 파라미터 추정의 분산을 비교</span>
- 교차검증과 유사한 절차
- 데이터의 일부를 기반으로 추정치를 계산 후, 다른 부분의 데이터를 사용해 추정치를 계속 재계산하는것
	- 이를 통해 추정치 주위의 신뢰도를 얻거나, 평규느 분산, 엔트로피 등 데이터 세트에서 테스트 하고 있는 수학적 신뢰구간을 계산


분석 결과에서 편향을 피하는 것
<span style="color:rgb(116, 195, 194)">모델이 보지 못한 데이터를 적용. 오버피팅된 훈련데이터는 테스트 데이터의 성능을 감소시킨다.</span> 
- 훈련 데이터 세트에서 과적합이 발생하지 않으면, 테스트 세트에서 더 나은 성능을 보임
- 훈련 세트와 테스트 세트에서 정말로 편향을 피하고 있는지 확신하는것은 까다롭다.

분류 정확도를 계산하는것
<span style="color:rgb(116, 195, 194)">교차검증으로 분류정확도를 계산하는것을 머신러닝과 딥러닝에서 가장 많이 사용됨</span> 


이상적으로, 테스트 데이터 세트는  훈련 데이터 세트와 순수하게 독립적이어야 한다.
<span style="color:rgb(118, 147, 234)">이것은 편향과 오버피팅을 피한다.</span> 
- 하지만 데이터를 분리한다고 해서 항상 훈련 데이터와 테스트 데이터가 완전히 독립적인것은 아님

당신의 데이터가 어떤 케이스인지 명심하라
<span style="color:rgb(116, 195, 194)">예를들어, 동일한 학교에서 자발적으로 참여한 학생들의 그룹</span> 
- 만약 학업성과에 대한 연구를 하고있고, 표본이 농구팀에 속해 있으며, 공상과학 영화를 좋아하는 학생들로만 구성되어있다면?
- 30명 중 27명을 훈련 데이터, 3명을 테스트 케이스로 나눔
	- 기술적으로는 훈련 데이터와 테스트 데이터를 분리
	- 이미 분리하기 전부터 학생들은 서로 매우 유사하하기 때문에 훈련 데이터는 사실상 테스트 데이터와 독립적이지 않다

**테스트 와 훈련 세트가 반드시 독립적이지는 않다.**
	