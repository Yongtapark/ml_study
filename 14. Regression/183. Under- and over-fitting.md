- 오버피팅과 언더피팅의 의미
- 모델 파라미터의 수와 오버피팅의 관계
- 오버피팅의 숨겨진 교묘한 형태
---
## The problem with overfitting

![183.Pasted image 20241004114804](../pic/14.%20Regression/183.Pasted%20image%2020241004114804.png)

	오버피팅이 좋지 않은 3가지 이유
	1. 통계의 목표는 가능한 한 단순한 모델을 사용하여 데이터를 피팅하는것.
	2. 많은 노이즈를 피팅하게 되는 것
	3. 일반화 가능성이 낮다.

![183.Pasted image 20241004114944](../pic/14.%20Regression/183.Pasted%20image%2020241004114944.png)

	두번째 모델에 비해 세번쨰 모델은 잘 동작하지 않음.

	일반적으로 통계를 할 때, 우리는 샘플 자체에 대해서 신경쓰기보다 샘플의 모집단에 신경을 쓴다.
	따라서 이 표본으로부터 다른 표본을 일반화할 수 없다면, 이 표본에서 전체 모집단으로 일반화 할수 있는 능력에 대한 신뢰도가 제한됨.

---
## The problem with underfitting

![183.Pasted image 20241004121411](../pic/14.%20Regression/183.Pasted%20image%2020241004121411.png)

	파라미터가 너무 적어서 동적 특성을 충분히 얻지 못함

---
## Over-and under-fitting : summary

#### <span style="color:rgb(118, 147, 234)">Overfitting</span>
- <span style="color:rgb(230, 122, 122)">전체적으로 노이즈에 민감하다.</span>
- <span style="color:rgb(116, 195, 194)">미묘한 효과에 대한 민감성 증가</span>
- <span style="color:rgb(230, 122, 122)">일반화 능력 감소</span>
- <span style="color:rgb(230, 122, 122)">파라미터가 많은 모델은 추정하기 어려움</span>
#### <span style="color:rgb(118, 147, 234)">Underfitting</span> 
- <span style="color:rgb(116, 195, 194)">이상치에 덜 민감함</span>
- <span style="color:rgb(230, 122, 122)">진짜 효과를 감지할 가능성 감소</span>
- <span style="color:rgb(230, 122, 122)">일반화 능력 감소</span>
- <span style="color:rgb(116, 195, 194)">파라미터가 더 잘 추정됨</span>
- <span style="color:rgb(116, 195, 194)">적은 데이터로도 좋은 결과</span>
---
## How to know the correct number of parameters?

 <span style="color:rgb(118, 147, 234)">1-2차원의 경우:</span><span style="color:rgb(116, 195, 194)"> 데이터를 시각화하고 정보 기반으로 결정</span>

 <span style="color:rgb(118, 147, 234)">3차원 이상의 경우:</span><span style="color:rgb(116, 195, 194)"> 공식적인 모델 비교를 수행</span> 

---
## Hidden overfitting: "researcher degrees of freedom"

	좋은 분석을 하고 싶어하지만, 데이터에 어떤 분석이 적절한지 확신하지 못하기 떄문에 일어나는 오버 피팅

<span style="color:rgb(118, 147, 234)">"Researcher degrees of freedom":</span>  <span style="color:rgb(116, 195, 194)">연구자는 데이터를 정리, 정돈, 선택하는 방법과 어떤 모델을 사용하고 얼마나 많은 모델을 실행할지에 대해 많은 선택권을 가짐</span>

<span style="color:rgb(205, 205, 81)">Example:</span> <span style="color:rgb(236, 158, 111)">동일한 데이터에 대해 모델 A, B, C를 테스트한다. 다른 기준으로 데이터를 다시 정리하고 세 모델을 다시 테스트한다. 그 후, 정리된 데이터로 모델 B</span> ($\alpha=.05$) <span style="color:rgb(236, 158, 111)">를 게시한다.</span>

<span style="color:rgb(230, 122, 122)">실제로 p-임계값은 무엇인가?</span>  <span style="color:rgb(230, 122, 122)">.05</span> < $\alpha$ < <span style="color:rgb(230, 122, 122)">.05*6 - .3</span> 

---
## How to avoid researcher overfitting

1) <span style="color:rgb(116, 195, 194)">전체 분석 파이프라인을 사전에 결정하라 (데이터 수집 전) 이 계획에서 벗어나는 모든 사항은 명확히 명시해야 함. (예 : 사전 등록된 보고서)</span>
2) <span style="color:rgb(205, 205, 81)">데이터의 일부 작은 샘플에서 분석 파이프라인을 탐색/개발한 후, 그 파이프라인을 나머지 데이터에 적용하라(비공식적 훈련/테스트셋)</span> 


		오버피팅, 언더피팅이 긍정적인 측면을 가질 수 있더눈 점을 인식하는 것이 중요
		만약 데이터셋이 작다면, 언더피팅쪽으로 기울이는것이 좋을 수 있음.
---
## Code : Unsupervised
```python
# plotting origin datasets
n = 10
x = np.random.randn(n)
y1 = x + np.random.randn(n)*0.6
d_set1 = np.vstack((x,y1)).T
fig, ax = plt.subplots(2,3)
ax[0][0].plot(d_set1[:,0],d_set1[:,1],'bs',markerfacecolor='none',markersize=6)
ax[0][0].set_xticks([])
ax[0][0].set_yticks([])
ax[0][0].set_ylabel('Dataset 1')


y2 = x + np.random.randn(n)*0.6
d_set2 = np.vstack((x,y2)).T
ax[1][0].plot(d_set2[:,0],d_set2[:,1],'bs',markerfacecolor='none',markersize=6)
ax[1][0].set_xticks([])
ax[1][0].set_yticks([])
ax[1][0].set_ylabel('Dataset 2')


#2-parameter model
pterms = np.polyfit(x,y1,2)
hat = np.polyval(pterms,x)

ax[0,1].plot(x,y1,'bs',markerfacecolor='none',markersize=6)
ax[0,1].plot([min(x),max(x)],[min(hat),max(hat)],'g--')
ax[0][1].set_xticks([])
ax[0][1].set_yticks([])

## compute r^2 and f
ss_ep = sum((y1-hat)**2)
ss_to = sum((y1-np.mean(y1))**2)
ss_mo = sum((hat-np.mean(y1))**2)
r2 = 1-(ss_ep/ss_to)
f = (ss_mo/2)/(ss_ep/7)
ax[0][1].set_title(f'$r^2$ =  {np.round(r2,2)}, f = {np.round(f,2)}')

ax[1,1].plot(x,y2,'bs',markerfacecolor='none',markersize=6)
ax[1,1].plot([min(x),max(x)],[min(hat),max(hat)],'g--',label='d')
ax[1][1].set_xticks([])
ax[1][1].set_yticks([])

## compute r^2 and f
ss_ep = sum((y2-hat)**2)
ss_to = sum((y2-np.mean(y2))**2)
ss_mo = sum((hat-np.mean(y2))**2)
r2 = 1-(ss_ep/ss_to)
f = (ss_mo/2)/(ss_ep/7)
ax[1][1].set_title(f'$r^2$ =  {np.round(r2,2)}, f= {np.round(f,2)}')



#10-parameter model
pterms = np.polyfit(x,y1,10)
hat = np.polyval(pterms,x)

ax[0][2].plot(x,y1,'bs',markerfacecolor='none',markersize=6)
ax[0][2].plot(x,hat,'r+',markersize=6)
ax[0][2].set_xticks([])
ax[0][2].set_yticks([])

## compute r^2 and f
ss_ep = sum((y1-hat)**2)
ss_to = sum((y1-np.mean(y1))**2)
ss_mo = sum((hat-np.mean(y1))**2)
r2 = 1-(ss_ep/ss_to)
# F-statistic cannot be computed because the degrees of freedom are negative
#f = (ss_mo/10)/(ss_ep/-1) 
ax[0][2].set_title(f'$r^2$ =  {np.round(r2,2)}, f= {np.nan}')

ax[1][2].plot(x,y2,'bs',markerfacecolor='none',markersize=6)
ax[1][2].plot(x,hat,'r+',markersize=6)
ax[1][2].set_xticks([])
ax[1][2].set_yticks([])

## compute r^2 and f
ss_ep = sum((y2-hat)**2)
ss_to = sum((y2-np.mean(y2))**2)
ss_mo = sum((hat-np.mean(y2))**2)
r2 = 1-(ss_ep/ss_to)
#f = (ss_mo/10)/(ss_ep/-1)
ax[1][2].set_title(f'$r^2$ =  {np.round(r2,2)}, f= {np.nan}')

plt.show()
```
![183.Pasted image 20241005205002](../pic/14.%20Regression/183.Pasted%20image%2020241005205002.png)
