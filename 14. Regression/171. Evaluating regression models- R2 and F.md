- 모델이 데이터에서 얼마나 잘 맞는지 평가하는 방법
- 회귀 모델의 자유도
- 각 회귀 파라미터$(\beta)$ 의 통계적 유의성을 평가하는 방법
---
## The model and the residuals

![171.Pasted image 20241001082216](../pic/14.%20Regression/171.Pasted%20image%2020241001082216.png)

#### $\epsilon$ = 모든 잔차 분산 또는 오차 분산
	모델이 데이터에 대해 예측하지 못한 모든것을 포함함

##### 중요한점 : 이 epsiolon이 너무 작지 않아야 한다.
	0에 가까워진다면, 이는 모델이 데이터를 완벽하게 맞춘다는것을 의미.
	만약 모델이 데이터를 완벽하게 적합한다면, 데이터가 너무 단순하거나, 모델이 너무 복잡해서 간소화되어야 한다는 것을 의미

통계학과 모델 적합의 목표 : 세상의 모든 변동성을 설명하는 것이 아니라, 세계의 엄청난 복잡성을 이해할 수 있도록 간소화된 모델을 개발하는 것

	epsilon을 풀어본다면
	
![171.Pasted image 20241001082745](../pic/14.%20Regression/171.Pasted%20image%2020241001082745.png)
$(\beta_0+\beta_1x_1+...+\beta_kx_k)$ : 모델에 기반해 예측한데이터 값들

![171.Pasted image 20241001083024](../pic/14.%20Regression/171.Pasted%20image%2020241001083024.png)
y-hat($\hat{y}$) : 잔차 항(epsilon)을 제외한 젠체 모델과 동일

![171.Pasted image 20241001083248](../pic/14.%20Regression/171.Pasted%20image%2020241001083248.png)
	실제 데이터와 예측된 데이터 간의 차이를 의미

---
## Evaluating a model fit with $R^2$

![171.Pasted image 20241001084423](../pic/14.%20Regression/171.Pasted%20image%2020241001084423.png)

$SS_{Total}$은 기존의 총제곱합과 동일하고,
$SS_{\epsilon}$은 평균이 아닌, 모델 예측값을 차감함

$R^2$ <span style="color:rgb(116, 195, 194)">값이 1에 가까우면 데이터에 잘 적합한다는 의미</span> 
$R^2$ <span style="color:rgb(116, 195, 194)">값이 0에 가까우면 데이터에 제대로 적합하지 않았다는 의미</span> 
$R^2$ <span style="color:rgb(116, 195, 194)">값이 0보다 작아질 수 있으며, 이는 오류 때문일것</span> - 실수를 했을 가능성이 높음

$R^2$<span style="color:rgb(230, 122, 122)">의 명확한 기준점은 존재하지 않음!</span>
	R제곱이 .62이니 좋은 적합도입니다. 같은 말을 할수는 없음
	절대적인 R제곱 값을 통계적으로 해석할 수 있는 임계값이 없음.

$R^2$<span style="color:rgb(236, 158, 111)">는 모델 간 비교에 자주 사용됨</span> 

$R^2$ : 모델 결과의 변동성이 얼마나 실제 결과의 변동성을 얼마나 잘 설명하는지 나타내는지표

---
## Evaluating model statistical significance with F

![171.Pasted image 20241001091419](../pic/14.%20Regression/171.Pasted%20image%2020241001091419.png)
우리의 귀무가설은, 베타 계수 1에서 k 까지가 모두 0 이라는 것을 나타냄
여기서 절편은 $\beta_{0}$ 라고 가정함. 따라서 귀무가설은 절편이 0이 아닌 값을 가질 수 있음

![171.Pasted image 20241001092709](../pic/14.%20Regression/171.Pasted%20image%2020241001092709.png)
그래서 y는 절편과 y-hat, 잔차의 합과 같다는 것. 이것이 귀무가설 하의 모델임

![171.Pasted image 20241001092139](../pic/14.%20Regression/171.Pasted%20image%2020241001092139.png)
대립 가설은 적어도 하나의 베타 계수가 0이 아니라는 것을 알려줌.
그러나 어떤것이, 몇개가 0이 아닌지는 알려주지 않음.

![171.Pasted image 20241001092620](../pic/14.%20Regression/171.Pasted%20image%2020241001092620.png)

	그렇다면 이 F 를 어떻게 계산할까? 
	이 대립 가설을 귀무가설에 비해 어떻게 평가할까?
	ANOVA에 서 F값을 구하는 방식과 비슷함.

![171.Pasted image 20241001093315](../pic/14.%20Regression/171.Pasted%20image%2020241001093315.png)

k : 절편을 포함한 모델의 전체 파라미터 수
	즉, 절편을 제외한 총 파라미터 수가 아니라는 점을 유의

	이 F 통계량은 정체 모델에 대한 정보를 제공한다. 각 개별 베타 계수에 대해 어떤것도 말해주지 않음
	이를 알아내기 위해서는 베타 계수에 대한 후속 분석이 필요

	F 통계량이 통계적으로 유의미 할 때만 후속 분석을 할 수 있음
	즉, 이 값의 우연에 의한 것보다 크다면, 일반적으로 모델이 데이터에 잘 맞는다는것을 의미
	그 다음에야 개별 베타 계수를 평가하는 다음단계로 넘어갈 수 있음


F 통계량 : 모델의 모든 독립변수들이 함께 종속변수에 영향을 미치는지 검정

---
## Significance of individual $\beta$ coefficients


![171.Pasted image 20241001102054](../pic/14.%20Regression/171.Pasted%20image%2020241001102054.png)

$\beta$ : 각각의 개별 베타

Important : k는 절편을 포함한 총 파라미터의 수, 절편을 제외하면 N-k+1이 됨

$\beta$ 계수 : 각 독립변수가 종속변수에 미치는 영향의  크기와 방향을 보여주며, p-value를 통해 그 유의성을 평가

