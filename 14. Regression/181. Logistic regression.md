- 정규회귀와 로지스틱 회귀의 차이
- 언제 회귀 분석이 로지스틱인지
- 로지스틱 회귀가 표준회귀와 어떻게 다른지
---
## What is a logistic regression?

<span style="color:rgb(118, 147, 234)">로지스틱 회귀 (a.k.a. 이진 로지스틱 회귀)는 이진(논리적) 종속변수를 가진다.</span>
<span style="color:rgb(118, 147, 234)">Examples:</span>
<span style="color:rgb(116, 195, 194)">참/거짓</span>
<span style="color:rgb(116, 195, 194)">남자/여자</span>
<span style="color:rgb(116, 195, 194)">양성종양/음성종양</span>
<span style="color:rgb(116, 195, 194)">승리/패배</span>

	종속 변수가 이항적이고 두 가지 중 하나의 답만을 취하는 모든 상황에서 로지스틱 회귀를 사용함

<span style="color:rgb(118, 147, 234)">어떤 수의 범주형 결과로도 확장할 수 있음(a.k.a. 다항 로지스틱 회귀)</span> 
<span style="color:rgb(116, 195, 194)">cat/penguin/truck</span> 

---
## What is the outcome of a logistic regression

<span style="color:rgb(118, 147, 234)">로지스틱 회귀는 분류를 수행하지 않음. 대신 범주에 속할 확률을 반환함.</span>

<span style="color:rgb(116, 195, 194)">분류는 예를 들어 r>.5 같은 임계값을 사용하여 구현할 수 있음</span>

---
## Setting up the logistic regression equation

![181.Pasted image 20241004085005](../pic/14.%20Regression/181.Pasted%20image%2020241004085005.png)
# $$p = \frac{1}{1+e^{-\hat{y}}}$$
	12. The Logistic function 강의 참고

---
## Why take the log of probabilities?

![181.Pasted image 20241004092725](../pic/14.%20Regression/181.Pasted%20image%2020241004092725.png)

$\frac{p}{1-p}$ : 승산비

<span style="color:rgb(236, 158, 111)">Main point:</span> <span style="color:rgb(205, 205, 81)">작은 값의 로그는 더 큰 동적 범위를 가지며, 최적화 문제에서 다루기 쉬움</span>

	파란색 선인 승산비는 그 차이가 너무 작아 그 차이를 구분 할수 없음. 
	하지만 자연로그를 취하면 그 차이가 명확해진다.

---
## How to find the best regression coefficients?

![181.Pasted image 20241004095147](../pic/14.%20Regression/181.Pasted%20image%2020241004095147.png)

	이 공식은 베타계수가 지수 형태로 들어가고 나누기도 존재하는 등 비선형성이 존재한다.

<span style="color:rgb(118, 147, 234)">계수의 비선형성은 왼쪽 역행렬이 유요한 해결책이 되는것을 방해함</span>

<span style="color:rgb(116, 195, 194)">대신, 경사하강법과 같은 반복적인 방법이 사용되어 확률이 종속변수와 잘 일치하도록 하는 파라미터 집합을 찾음</span>

	랜덤한 베타값을 선택한 후, 베타가 관측된 데이터와 일치하는 좋은 솔루션에 더 가까워질때까지 반복하는것

---
## Example logistic regression

<span style="color:rgb(118, 147, 234)">Research question:</span>  <span style="color:rgb(116, 195, 194)">수면 시간과 공부 시간이 시험을 합격하는 것을 예측할 수 있는가?</span>

<span style="color:rgb(118, 147, 234)">Experiment:</span>  <span style="color:rgb(116, 195, 194)">학생들(N=20)자신의 수면 시간과 공부한 시간을 보고하도록 요청한다. 시험이 끝난 후 대학의 보안 네트워크에 침입해 그 학생들의 성적을 찾아내고, 훔친다. 프라이버시를 위해 각 성적을 합격 또는 불합격으로 분류한다.</span> 

---
## Example logistic regression

![181.Pasted image 20241004102122](../pic/14.%20Regression/181.Pasted%20image%2020241004102122.png)

	로지스틱 회귀에서는 절편을 보통 해석하지 않음.

	현재 여기서 나오는 베타계수는 표준화되지 않은 베타계수이므로 서로 다른 계수들을 비교하지 말아야 함
	하지만 이번 경우는 척도가 동일(Hours sleeep or study)하기 떄문에 직접 비교가 가능함

---
## Example logistic regression

	각 개인이 합격할 확률

![181.Pasted image 20241004102951](../pic/14.%20Regression/181.Pasted%20image%2020241004102951.png)

	중앙선 기준 왼쪽 부분은 시험에 탈락한 인원 오른쪽 부분은 합격한 인원

2,3사분면 : 실제 예측대로 통과/탈락한 인원

---
## Code: 공부시간, 수면시간과 합격 불합격의 관계

```python
## generate the data

exam_outcome = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1];
study_hours  = [7.9, 7.9, 2.8, 5.4, 6.1, 4.5, 6.9, 2.3, 1.9, 1, 3.1, 5.7, 5.6, 4.7, 4.2, 2, 7.7, 6.5, 5.1, 3.7]
sleep_hours  = [4.4, 5.2, 7.5, 4.6, 5.5, 6.1, 6.6, 3.1, 5.9, 3.2, 7.5, 7.8, 6.1, 5.4, 10.5, 8.2, 7.2, 7.2, 5.9, 7.9]

n = len(exam_outcome)

# and plot
for i in range(n):
    plt.plot([exam_outcome[i]-.05,exam_outcome[i]+.05],[study_hours[i],sleep_hours[i]],color=[.7,.7,.7])

plt.plot(exam_outcome-.05*np.ones(n),study_hours,'ks',markerfacecolor=[1,.8,1],label='Study')
plt.plot(exam_outcome+.05*np.ones(n),sleep_hours,'ks',markerfacecolor=[.39,1,1],label='Sleep')

plt.xticks([0,1],labels=('Fail','Pass'))
plt.xlim([-.5,1.5])
plt.ylabel('Hours sleep or study')
plt.legend()
plt.show()
```
![181.Pasted image 20241004111441](../pic/14.%20Regression/181.Pasted%20image%2020241004111441.png)

```python
## now for the logistic regression

# create a model
logregmodel = LogisticRegression(solver='newton-cg')

# create the design matrix
desmat = np.vstack((study_hours,sleep_hours)).T

logregmodel.fit(desmat,np.array(exam_outcome))

print(logregmodel.intercept_)
print(logregmodel.coef_)
```
```
[-7.15491116]
[[0.10742138 1.05067754]]
```

로지스틱 모델로 예측을 시행하고, 실제 결과와 예측 결과를 비교
```python
# compute predictions and accuracy

predvals = logregmodel.predict(desmat) # class Labels
predvalsP = logregmodel.predict_proba(desmat) # probability values

print(predvals)
print(np.array(exam_outcome))

print(predvalsP)

logregmodel.score(desmat,np.array(exam_outcome))
```
```
[0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1]
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]
[[0.84334115 0.15665885]
 [0.69904598 0.30095402]
 [0.26386998 0.73613002]
 [0.85090528 0.14909472]
 [0.67280831 0.32719169]
 [0.56522173 0.43477827]
 [0.37267263 0.62732737]
 [0.9746856  0.0253144 ]
 [0.67957362 0.32042638]
 [0.97552495 0.02447505]
 [0.25765805 0.74234195]
 [0.16074767 0.83925233]
 [0.53599224 0.46400776]
 [0.72638774 0.27361226]
 [0.01301731 0.98698269]
 [0.15769393 0.84230607]
 [0.22493912 0.77506088]
 [0.24820547 0.75179453]
 [0.60062372 0.39937628]
 [0.17611402 0.82388598]]

0.75
```

```python
# plotting

fig, ax = plt.subplots(1,1,figsize=(5,5))

ax.plot(predvalsP[:,1],'ks')
ax.plot([0,19],[.5,.5],'b--')
ax.plot([9.5,9.5],[0,1],'b--')

ax.set_xticks(np.arange(20))
ax.set_xlabel('Individual')
ax.set_ylabel('p(pass)')
ax.set_xlim([-.5,19.5])
ax.set_ylim([0,1])
plt.show()
```
![181.Pasted image 20241004111537](../pic/14.%20Regression/181.Pasted%20image%2020241004111537.png)
